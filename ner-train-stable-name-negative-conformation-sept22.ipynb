{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:25:59.864776Z","iopub.execute_input":"2024-09-22T17:25:59.865419Z","iopub.status.idle":"2024-09-22T17:26:00.231348Z","shell.execute_reply.started":"2024-09-22T17:25:59.865378Z","shell.execute_reply":"2024-09-22T17:26:00.230413Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d8429083ca14e1b87033bd3c580d5a9"}},"metadata":{}}]},{"cell_type":"code","source":"%%capture\n!pip install datasets --no-build-isolation\n!pip install seqeval\n!pip install transformers[torch]","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:26:35.319095Z","iopub.execute_input":"2024-09-22T17:26:35.319972Z","iopub.status.idle":"2024-09-22T17:27:22.393775Z","shell.execute_reply.started":"2024-09-22T17:26:35.319929Z","shell.execute_reply":"2024-09-22T17:27:22.392676Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback\nimport torch\nimport numpy as np\nfrom datasets import load_metric","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:27:22.395715Z","iopub.execute_input":"2024-09-22T17:27:22.396052Z","iopub.status.idle":"2024-09-22T17:27:45.023504Z","shell.execute_reply.started":"2024-09-22T17:27:22.396016Z","shell.execute_reply":"2024-09-22T17:27:45.022668Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = load_dataset(\"procit002/FirstnameOnlyAug06\",token =\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:27:45.024672Z","iopub.execute_input":"2024-09-22T17:27:45.025279Z","iopub.status.idle":"2024-09-22T17:27:46.786365Z","shell.execute_reply.started":"2024-09-22T17:27:45.025243Z","shell.execute_reply":"2024-09-22T17:27:46.785460Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/2.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"219ee4508ccd42fa9486debd45905584"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/140k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7714757f106487a817e091b11c902b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8805 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"832411016e464976841bc3dd82150709"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:27:46.788599Z","iopub.execute_input":"2024-09-22T17:27:46.788923Z","iopub.status.idle":"2024-09-22T17:27:46.795676Z","shell.execute_reply.started":"2024-09-22T17:27:46.788891Z","shell.execute_reply":"2024-09-22T17:27:46.794667Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 8805\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Model checkpoint\ncheckpoint = \"procit008/NER_train_Stable_negative_conformation_sept22\"\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:27:46.796970Z","iopub.execute_input":"2024-09-22T17:27:46.797246Z","iopub.status.idle":"2024-09-22T17:27:47.536270Z","shell.execute_reply.started":"2024-09-22T17:27:46.797216Z","shell.execute_reply":"2024-09-22T17:27:47.535451Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30003a5456d7464189227d19c3083af2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab7fa8d9879546d499727a0a91a66f09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b12a9f59dc5c4232ae2eb28ed3208303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e4cb7cd2044b86849ab6340c8ced42"}},"metadata":{}}]},{"cell_type":"code","source":"# Tokenize and align labels without fixed padding\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\ntokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:28:31.630028Z","iopub.execute_input":"2024-09-22T17:28:31.630810Z","iopub.status.idle":"2024-09-22T17:28:32.321264Z","shell.execute_reply.started":"2024-09-22T17:28:31.630763Z","shell.execute_reply":"2024-09-22T17:28:32.320302Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8805 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4938e3c40dc34bfbb2ae98df5dee9107"}},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained model\nmodel = AutoModelForTokenClassification.from_pretrained(checkpoint, num_labels=9)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:28:33.721326Z","iopub.execute_input":"2024-09-22T17:28:33.722082Z","iopub.status.idle":"2024-09-22T17:28:35.828609Z","shell.execute_reply.started":"2024-09-22T17:28:33.722036Z","shell.execute_reply":"2024-09-22T17:28:35.827731Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84006cec5fb44d848251bab58a75c458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c062a29cd0bb4f3b931cdfb28c96f323"}},"metadata":{}}]},{"cell_type":"code","source":"# Load seqeval metric\nmetric = load_metric(\"seqeval\")\n\n# Define compute_metrics function\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:28:44.593540Z","iopub.execute_input":"2024-09-22T17:28:44.593959Z","iopub.status.idle":"2024-09-22T17:28:44.760786Z","shell.execute_reply.started":"2024-09-22T17:28:44.593921Z","shell.execute_reply":"2024-09-22T17:28:44.759942Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Get label list\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n\n# Set up data collator for dynamic padding\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:28:45.566051Z","iopub.execute_input":"2024-09-22T17:28:45.567028Z","iopub.status.idle":"2024-09-22T17:28:45.572030Z","shell.execute_reply.started":"2024-09-22T17:28:45.566983Z","shell.execute_reply":"2024-09-22T17:28:45.571091Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_scheduler, TrainingArguments, Trainer, EarlyStoppingCallback\n\n# Assuming model, tokenizer, data_collator, tokenized_datasets, and compute_metrics are already defined\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./stable_version_on_name_negative_and_conformation_NER_sep22\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=4,\n    weight_decay=0.01,  # Weight decay for L2 regularization\n    load_best_model_at_end=True,  # Load the best model when early stopping is triggered\n    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n    greater_is_better=False,\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:31:48.504433Z","iopub.execute_input":"2024-09-22T17:31:48.505498Z","iopub.status.idle":"2024-09-22T17:31:48.544314Z","shell.execute_reply.started":"2024-09-22T17:31:48.505433Z","shell.execute_reply":"2024-09-22T17:31:48.543228Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Initialize an optimizer\noptimizer = AdamW(\n    model.parameters(),\n    lr=training_args.learning_rate,\n    weight_decay=training_args.weight_decay\n)\n\n# Define the scheduler (optional, here using a linear scheduler with warmup)\nlr_scheduler = get_scheduler(\n    name=\"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,  # Number of warmup steps (you can change this)\n    num_training_steps=len(tokenized_datasets[\"train\"]) // training_args.per_device_train_batch_size * training_args.num_train_epochs,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:31:49.128465Z","iopub.execute_input":"2024-09-22T17:31:49.129242Z","iopub.status.idle":"2024-09-22T17:31:49.141771Z","shell.execute_reply.started":"2024-09-22T17:31:49.129201Z","shell.execute_reply":"2024-09-22T17:31:49.140599Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if validation split exists, if not fallback to test split or create one\nif \"validation\" not in tokenized_datasets:\n    # Split the training set if validation doesn't exist\n    train_test_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.1)  # 10% for validation\n    tokenized_datasets[\"train\"] = train_test_split[\"train\"]\n    tokenized_datasets[\"validation\"] = train_test_split[\"test\"]\n\n# Initialize Trainer with compute_metrics and data collator\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, lr_scheduler),  # Pass the optimizer and scheduler to the Trainer\n   # callbacks=[early_stopping_callback]  # Include early stoppingÂ callback\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:38:24.520073Z","iopub.execute_input":"2024-09-22T17:38:24.520527Z","iopub.status.idle":"2024-09-22T17:38:25.895503Z","shell.execute_reply.started":"2024-09-22T17:38:24.520485Z","shell.execute_reply":"2024-09-22T17:38:25.894641Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:38:32.270278Z","iopub.execute_input":"2024-09-22T17:38:32.270699Z","iopub.status.idle":"2024-09-22T17:42:21.919973Z","shell.execute_reply.started":"2024-09-22T17:38:32.270660Z","shell.execute_reply":"2024-09-22T17:42:21.919145Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240922_173853-su00i0og</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dulalsusan773-procit-bv/huggingface/runs/su00i0og' target=\"_blank\">./stable_version_on_name_negative_and_conformation_NER_sep22</a></strong> to <a href='https://wandb.ai/dulalsusan773-procit-bv/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dulalsusan773-procit-bv/huggingface' target=\"_blank\">https://wandb.ai/dulalsusan773-procit-bv/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dulalsusan773-procit-bv/huggingface/runs/su00i0og' target=\"_blank\">https://wandb.ai/dulalsusan773-procit-bv/huggingface/runs/su00i0og</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [992/992 03:09, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.000006</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.000004</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.040600</td>\n      <td>0.000004</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.040600</td>\n      <td>0.000003</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=992, training_loss=0.020485145349201987, metrics={'train_runtime': 229.0173, 'train_samples_per_second': 138.4, 'train_steps_per_second': 4.332, 'total_flos': 93017324868552.0, 'train_loss': 0.020485145349201987, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate model\nresults = trainer.evaluate()\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:43:08.899813Z","iopub.execute_input":"2024-09-22T17:43:08.900784Z","iopub.status.idle":"2024-09-22T17:43:10.807299Z","shell.execute_reply.started":"2024-09-22T17:43:08.900739Z","shell.execute_reply":"2024-09-22T17:43:10.806101Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 3.0135320230328944e-06, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 1.8915, 'eval_samples_per_second': 465.768, 'eval_steps_per_second': 14.803, 'epoch': 4.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.push_to_hub(\"stable_version_on_name_negative_and_conformation_NER_sep22\")\ntokenizer.push_to_hub(\"stable_version_on_name_negative_and_conformation_NER_sep22\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:43:42.683729Z","iopub.execute_input":"2024-09-22T17:43:42.684125Z","iopub.status.idle":"2024-09-22T17:44:02.616934Z","shell.execute_reply.started":"2024-09-22T17:43:42.684085Z","shell.execute_reply":"2024-09-22T17:44:02.615750Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f7a9629c8db412b831b97372181de0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1727026990.bfc4b5d20d9e.36.1:   0%|          | 0.00/560 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a49a972054490e9b44e8218609e9f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1727026712.bfc4b5d20d9e.36.0:   0%|          | 0.00/7.96k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8098b4b93901407baa72e6f4388c8725"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dab6b4b5c424f35adedc39122e4a371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b363e2ca9d492c8b18e6cbe0cfb601"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33641d94c4114c2790f333ef1eb8d8b3"}},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/procit008/stable_version_on_name_negative_and_conformation_NER_sep22/commit/f8c187b0dc6c87d1d8136a4544f906dfba567fcc', commit_message='Upload tokenizer', commit_description='', oid='f8c187b0dc6c87d1d8136a4544f906dfba567fcc', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}