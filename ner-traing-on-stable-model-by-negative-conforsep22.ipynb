{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-22T14:23:14.782672Z","iopub.execute_input":"2024-09-22T14:23:14.783626Z","iopub.status.idle":"2024-09-22T14:23:15.247117Z","shell.execute_reply.started":"2024-09-22T14:23:14.783579Z","shell.execute_reply":"2024-09-22T14:23:15.246133Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b852a701ad4d9a82bafdebb82b83e2"}},"metadata":{}}]},{"cell_type":"code","source":"%%capture\n!pip install datasets --no-build-isolation\n!pip install seqeval\n!pip install transformers[torch]","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:23:36.658133Z","iopub.execute_input":"2024-09-22T14:23:36.658516Z","iopub.status.idle":"2024-09-22T14:24:23.807623Z","shell.execute_reply.started":"2024-09-22T14:23:36.658478Z","shell.execute_reply":"2024-09-22T14:24:23.806282Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback\nimport torch\nimport numpy as np\nfrom datasets import load_metric","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:24:23.809851Z","iopub.execute_input":"2024-09-22T14:24:23.810192Z","iopub.status.idle":"2024-09-22T14:24:53.692672Z","shell.execute_reply.started":"2024-09-22T14:24:23.810156Z","shell.execute_reply":"2024-09-22T14:24:53.691635Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install datasets huggingface-hub","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:24:53.694063Z","iopub.execute_input":"2024-09-22T14:24:53.694846Z","iopub.status.idle":"2024-09-22T14:25:07.047223Z","shell.execute_reply.started":"2024-09-22T14:24:53.694780Z","shell.execute_reply":"2024-09-22T14:25:07.045925Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = load_dataset(\"procit002/Ner_NegativeAnswer_and_ConfirmationAnswer\",token =\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:07.050846Z","iopub.execute_input":"2024-09-22T14:25:07.051241Z","iopub.status.idle":"2024-09-22T14:25:17.876565Z","shell.execute_reply.started":"2024-09-22T14:25:07.051203Z","shell.execute_reply":"2024-09-22T14:25:17.875553Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/2.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3022b125d754813895c3665b8134c54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/392k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c18e42e51048498a845bd9343193b296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e78b9184c5f440984c6636a7c5d9b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/53.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94375781da054434a376e63995c20e76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14125 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3b255dd55bb467985b85313279cb02b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49caa4c2a25e417da45dc73363121580"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b80ddc791fa466e85eff392d4e06b7f"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:17.877921Z","iopub.execute_input":"2024-09-22T14:25:17.878314Z","iopub.status.idle":"2024-09-22T14:25:17.885788Z","shell.execute_reply.started":"2024-09-22T14:25:17.878268Z","shell.execute_reply":"2024-09-22T14:25:17.884832Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14125\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 1766\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 1766\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Model checkpoint\ncheckpoint = \"procit002/NER_ServerStable_v0\"\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(checkpoint,token = \"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\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:17.886989Z","iopub.execute_input":"2024-09-22T14:25:17.887292Z","iopub.status.idle":"2024-09-22T14:25:21.378226Z","shell.execute_reply.started":"2024-09-22T14:25:17.887259Z","shell.execute_reply":"2024-09-22T14:25:21.377297Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592c84fc7b2b4238ac3a12507b2ccab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b647a2ffdc42938cc8e26464456dfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"164f270228ae499ca7676a0d70bce661"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6805a8856a3a4bb58f370e5f11c3bf13"}},"metadata":{}}]},{"cell_type":"code","source":"# Tokenize and align labels without fixed padding\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\ntokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:21.379444Z","iopub.execute_input":"2024-09-22T14:25:21.379771Z","iopub.status.idle":"2024-09-22T14:25:23.324057Z","shell.execute_reply.started":"2024-09-22T14:25:21.379735Z","shell.execute_reply":"2024-09-22T14:25:23.323059Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14125 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da878610cef4f81b297c2985eff4d03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfe5ed056d234d658bc0b1158e2c27e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cfc71f20c5444fdb67f27b319c0e67d"}},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained model\nmodel = AutoModelForTokenClassification.from_pretrained(checkpoint, num_labels=9)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:23.325345Z","iopub.execute_input":"2024-09-22T14:25:23.325683Z","iopub.status.idle":"2024-09-22T14:25:39.499958Z","shell.execute_reply.started":"2024-09-22T14:25:23.325648Z","shell.execute_reply":"2024-09-22T14:25:39.499097Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8034b0ca52a4e6bb4475a8eecf9516e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6bb202b10c4ff2b021750a1128ec5b"}},"metadata":{}}]},{"cell_type":"code","source":"# Load seqeval metric\nmetric = load_metric(\"seqeval\")\n\n# Define compute_metrics function\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:26:03.153186Z","iopub.execute_input":"2024-09-22T14:26:03.153955Z","iopub.status.idle":"2024-09-22T14:26:03.194052Z","shell.execute_reply.started":"2024-09-22T14:26:03.153913Z","shell.execute_reply":"2024-09-22T14:26:03.192488Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load seqeval metric\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[43mload_metric\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseqeval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define compute_metrics function\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(p):\n","\u001b[0;31mNameError\u001b[0m: name 'load_metric' is not defined"],"ename":"NameError","evalue":"name 'load_metric' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Get label list\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n\n# Set up data collator for dynamic padding\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_scheduler, TrainingArguments, Trainer, EarlyStoppingCallback\n\n# Assuming model, tokenizer, data_collator, tokenized_datasets, and compute_metrics are already defined\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./stable_version_on_negative_and_conformation_NER_sep22\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=4,\n    weight_decay=0.01,  # Weight decay for L2 regularization\n    load_best_model_at_end=True,  # Load the best model when early stopping is triggered\n    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n    greater_is_better=False,\n    gradient_accumulation_steps=1,  # Accumulate gradients over 1 step (can adjust for larger batches)\n    fp16=True,  # Enable mixed precision to improve training speed and memory efficiency\n    logging_dir='./logs',  # Directory for storing logs\n    logging_steps=10,  # Log every 10 steps\n    gradient_checkpointing=True,  # For larger models to save memory\n    report_to=\"none\",  # Disable report to any online platforms\n   # max_grad_norm=1.0  # Gradient clipping to prevent exploding gradients\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:43.269367Z","iopub.execute_input":"2024-09-22T14:25:43.269829Z","iopub.status.idle":"2024-09-22T14:25:43.404767Z","shell.execute_reply.started":"2024-09-22T14:25:43.269767Z","shell.execute_reply":"2024-09-22T14:25:43.403728Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Initialize an optimizer\noptimizer = AdamW(\n    model.parameters(),\n    lr=training_args.learning_rate,\n    weight_decay=training_args.weight_decay\n)\n\n# Define the scheduler (optional, here using a linear scheduler with warmup)\nlr_scheduler = get_scheduler(\n    name=\"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,  # Number of warmup steps (you can change this)\n    num_training_steps=len(tokenized_datasets[\"train\"]) // training_args.per_device_train_batch_size * training_args.num_train_epochs,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:43.406186Z","iopub.execute_input":"2024-09-22T14:25:43.406616Z","iopub.status.idle":"2024-09-22T14:25:44.068990Z","shell.execute_reply.started":"2024-09-22T14:25:43.406569Z","shell.execute_reply":"2024-09-22T14:25:44.068017Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize Trainer with compute_metrics and data collator\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, lr_scheduler),  # Pass the optimizer and scheduler to the Trainer\n   # callbacks=[early_stopping_callback]  # Include early stopping callback\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:44.070529Z","iopub.execute_input":"2024-09-22T14:25:44.071426Z","iopub.status.idle":"2024-09-22T14:25:44.456577Z","shell.execute_reply.started":"2024-09-22T14:25:44.071365Z","shell.execute_reply":"2024-09-22T14:25:44.455732Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Set up training arguments\n# training_args = TrainingArguments(\n#     output_dir=\"./stable_version_on_negative_and_conformation_NER_sep22\",\n#     eval_strategy=\"epoch\",\n#     save_strategy = \"epoch\",\n#     learning_rate=1e-5,\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=16,\n#     num_train_epochs=4,\n#     weight_decay=0.01,\n#     num_warmup_steps = 0,  \n#     load_best_model_at_end=True,        # Load the best model when early stopping is triggered\n#     metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping (can be adjusted)\n#     greater_is_better=False\n# )\n\n# early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:44.457682Z","iopub.execute_input":"2024-09-22T14:25:44.458019Z","iopub.status.idle":"2024-09-22T14:25:44.462818Z","shell.execute_reply.started":"2024-09-22T14:25:44.457987Z","shell.execute_reply":"2024-09-22T14:25:44.461932Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # Initialize Trainer with compute_metrics and data collator\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=tokenized_datasets[\"train\"],\n#     eval_dataset=tokenized_datasets[\"validation\"],\n#     tokenizer=tokenizer,\n#     data_collator=data_collator,\n#     compute_metrics=compute_metrics,\n#     #callbacks=[early_stopping_callback]\n# )","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:44.464117Z","iopub.execute_input":"2024-09-22T14:25:44.464490Z","iopub.status.idle":"2024-09-22T14:25:44.472921Z","shell.execute_reply.started":"2024-09-22T14:25:44.464447Z","shell.execute_reply":"2024-09-22T14:25:44.471980Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:25:44.474219Z","iopub.execute_input":"2024-09-22T14:25:44.474551Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate model\nresults = trainer.evaluate()\nprint(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub(\"Procit008/able_version_on_negative_and_conformation_NER_sep20\")\ntokenizer.push_to_hub(\"Procit008/able_version_on_negative_and_conformation_NER_sep20\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}