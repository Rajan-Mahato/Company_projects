{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets huggingface-hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-19T04:32:20.247548Z","iopub.execute_input":"2024-09-19T04:32:20.247873Z","iopub.status.idle":"2024-09-19T04:32:35.151012Z","shell.execute_reply.started":"2024-09-19T04:32:20.247841Z","shell.execute_reply":"2024-09-19T04:32:35.149897Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.12.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:33:12.881290Z","iopub.execute_input":"2024-09-19T04:33:12.881667Z","iopub.status.idle":"2024-09-19T04:33:13.188006Z","shell.execute_reply.started":"2024-09-19T04:33:12.881631Z","shell.execute_reply":"2024-09-19T04:33:13.187123Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaeb554745bd47828a106e840cec2bca"}},"metadata":{}}]},{"cell_type":"code","source":"%%capture\n!pip install datasets --no-build-isolation\n!pip install seqeval\n!pip install transformers[torch]","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:36:57.950049Z","iopub.execute_input":"2024-09-19T04:36:57.951009Z","iopub.status.idle":"2024-09-19T04:37:41.534751Z","shell.execute_reply.started":"2024-09-19T04:36:57.950963Z","shell.execute_reply":"2024-09-19T04:37:41.533556Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback\nimport torch\nimport numpy as np\nfrom datasets import load_metric","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:46:21.393800Z","iopub.execute_input":"2024-09-19T06:46:21.394716Z","iopub.status.idle":"2024-09-19T06:46:21.400190Z","shell.execute_reply.started":"2024-09-19T06:46:21.394677Z","shell.execute_reply":"2024-09-19T06:46:21.399257Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = load_dataset(\"procit002/conll2003AndNameStreetCitySep18_and_negative_words_ConfirmationAnswer\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:46:24.530655Z","iopub.execute_input":"2024-09-19T06:46:24.531032Z","iopub.status.idle":"2024-09-19T06:46:26.104730Z","shell.execute_reply.started":"2024-09-19T06:46:24.530996Z","shell.execute_reply":"2024-09-19T06:46:26.103727Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:46:29.404483Z","iopub.execute_input":"2024-09-19T06:46:29.405537Z","iopub.status.idle":"2024-09-19T06:46:29.413426Z","shell.execute_reply.started":"2024-09-19T06:46:29.405483Z","shell.execute_reply":"2024-09-19T06:46:29.411936Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 98151\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 13764\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 13969\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Model checkpoint\ncheckpoint = \"bert-base-cased\"\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:46:33.112833Z","iopub.execute_input":"2024-09-19T06:46:33.113536Z","iopub.status.idle":"2024-09-19T06:46:33.247257Z","shell.execute_reply.started":"2024-09-19T06:46:33.113493Z","shell.execute_reply":"2024-09-19T06:46:33.245530Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize and align labels without fixed padding\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\ntokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:46:39.330791Z","iopub.execute_input":"2024-09-19T06:46:39.331223Z","iopub.status.idle":"2024-09-19T06:46:49.577861Z","shell.execute_reply.started":"2024-09-19T06:46:39.331167Z","shell.execute_reply":"2024-09-19T06:46:49.576814Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/98151 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30a6c6b517494dd19474394f34653792"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13764 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"711480b6ea744f5d8f41d6d5269e6a26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13969 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0700e0f708634d3cac38d35d51d7182d"}},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained model\nmodel = AutoModelForTokenClassification.from_pretrained(checkpoint, num_labels=9)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:46:56.348652Z","iopub.execute_input":"2024-09-19T06:46:56.349049Z","iopub.status.idle":"2024-09-19T06:46:56.593099Z","shell.execute_reply.started":"2024-09-19T06:46:56.349010Z","shell.execute_reply":"2024-09-19T06:46:56.592113Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load seqeval metric\nmetric = load_metric(\"seqeval\")\n\n# Define compute_metrics function\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:47:03.466622Z","iopub.execute_input":"2024-09-19T06:47:03.467009Z","iopub.status.idle":"2024-09-19T06:47:03.856556Z","shell.execute_reply.started":"2024-09-19T06:47:03.466971Z","shell.execute_reply":"2024-09-19T06:47:03.855583Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Get label list\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n\n# Set up data collator for dynamic padding\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:47:08.664376Z","iopub.execute_input":"2024-09-19T06:47:08.664796Z","iopub.status.idle":"2024-09-19T06:47:08.672556Z","shell.execute_reply.started":"2024-09-19T06:47:08.664757Z","shell.execute_reply":"2024-09-19T06:47:08.671439Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./NER\",\n    eval_strategy=\"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    load_best_model_at_end=True,        # Load the best model when early stopping is triggered\n    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping (can be adjusted)\n    greater_is_better=False\n)\n\nearly_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:49:18.923231Z","iopub.execute_input":"2024-09-19T06:49:18.924096Z","iopub.status.idle":"2024-09-19T06:49:18.964236Z","shell.execute_reply.started":"2024-09-19T06:49:18.924052Z","shell.execute_reply":"2024-09-19T06:49:18.963536Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Initialize Trainer with compute_metrics and data collator\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    callbacks=[early_stopping_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:49:21.728795Z","iopub.execute_input":"2024-09-19T06:49:21.729170Z","iopub.status.idle":"2024-09-19T06:49:21.749058Z","shell.execute_reply.started":"2024-09-19T06:49:21.729133Z","shell.execute_reply":"2024-09-19T06:49:21.748145Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:49:26.188853Z","iopub.execute_input":"2024-09-19T06:49:26.189353Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1793' max='30680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1793/30680 06:37 < 1:46:57, 4.50 it/s, Epoch 0.58/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate model\nresults = trainer.evaluate()\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:16:42.588308Z","iopub.execute_input":"2024-09-19T06:16:42.588725Z","iopub.status.idle":"2024-09-19T06:16:46.613973Z","shell.execute_reply.started":"2024-09-19T06:16:42.588686Z","shell.execute_reply":"2024-09-19T06:16:46.612877Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [52/52 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 5.768160553998314e-05, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 4.0089, 'eval_samples_per_second': 409.093, 'eval_steps_per_second': 12.971, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.push_to_hub(\"procit008/NER_test_conformation_answer\")\ntokenizer.push_to_hub(\"procit008/NER_test_conformation_answer\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:21:28.782767Z","iopub.execute_input":"2024-09-19T06:21:28.783168Z","iopub.status.idle":"2024-09-19T06:21:33.164651Z","shell.execute_reply.started":"2024-09-19T06:21:28.783129Z","shell.execute_reply":"2024-09-19T06:21:33.163550Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/procit008/NER_test_conformation_answer/commit/7657ab8dec0fe44ceae492772c828877ea881ee3', commit_message='Upload tokenizer', commit_description='', oid='7657ab8dec0fe44ceae492772c828877ea881ee3', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertConfig","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = BertConfig.from_pretrained(checkpoint)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom transformers import pipeline\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"procit008/NER\")\nmodel = AutoModelForTokenClassification.from_pretrained(\"procit008/NER\")\ndataset = load_dataset(\"conll2002\", 'nl')\nnlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\nexample = \"My name is Wolfgang and I live in Berlin\"\n\nner_results = nlp(example)\nprint(ner_results)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:30:34.186941Z","iopub.execute_input":"2024-09-19T06:30:34.187375Z","iopub.status.idle":"2024-09-19T06:31:05.279804Z","shell.execute_reply.started":"2024-09-19T06:30:34.187335Z","shell.execute_reply":"2024-09-19T06:31:05.278927Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6840e7e1aae4dbf95927573924f4345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc200dad200d4630868f9c241906a244"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f752e6cfca34842aab8289a5036ce15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b83db850d24b37ba6b6a6319ca78a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b3f958394f843af95863e904e6df3f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/431M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e496e954625147859e663d3e5161d146"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cbb32c3a1be4c6e9b50251a53420adf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/12.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee43cdb908647d0b872dbd8bd03394d"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for conll2002 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2002.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  Y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/571k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85bcaf6a321f43daa7f8bc3a0f49422c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd8b023873834dd8b3faa74d568fe4be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/194k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bb30d1d8bcb457899e004d64fa6bedb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/15807 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc35f3842ca143bdb4201c9f51f27379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2896 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3ee75681944f27bacd40c4ee6eda77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5196 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd39562de1b24e928425935345f91667"}},"metadata":{}},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"[{'entity': 'LABEL_0', 'score': 0.99991894, 'index': 1, 'word': 'My', 'start': 0, 'end': 2}, {'entity': 'LABEL_0', 'score': 0.99990904, 'index': 2, 'word': 'name', 'start': 3, 'end': 7}, {'entity': 'LABEL_0', 'score': 0.99989164, 'index': 3, 'word': 'is', 'start': 8, 'end': 10}, {'entity': 'LABEL_1', 'score': 0.94205797, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'LABEL_0', 'score': 0.9997439, 'index': 5, 'word': 'and', 'start': 20, 'end': 23}, {'entity': 'LABEL_0', 'score': 0.9999007, 'index': 6, 'word': 'I', 'start': 24, 'end': 25}, {'entity': 'LABEL_0', 'score': 0.99736565, 'index': 7, 'word': 'live', 'start': 26, 'end': 30}, {'entity': 'LABEL_0', 'score': 0.7104487, 'index': 8, 'word': 'in', 'start': 31, 'end': 33}, {'entity': 'LABEL_2', 'score': 0.8114601, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n","output_type":"stream"}]},{"cell_type":"code","source":"def aggregate_word_level_predictions(tokenized_sentence, predictions, dataset):\n    print(\"tokenized_sentence\",tokenized_sentence)\n    print(\"predictions\",predictions)\n    aggregated_predictions = []\n    current_word = \"\"\n    current_entity = \"\"\n\n    for token, pred in zip(tokenized_sentence, predictions):\n        if token.startswith(\"##\"):\n            print(\"token\",token)\n            current_word += token[2:]  # Append sub-token to current word\n            print(\"current_word\",current_word)\n        else:\n            if current_word:  # If there's a current word, add it with its entity\n                aggregated_predictions.append((current_word, current_entity))\n                print(\"aggregated_predictions\",aggregated_predictions)\n            # Update the current word and entity\n            current_word = token if token not in [\"[CLS]\", \"[SEP]\"] else \"\"\n            print(\"current_word\",current_word)\n            current_entity = dataset['train'].features['ner_tags'].feature.int2str(pred.item())\n            print(\"current_entity\",current_entity)\n\n    # Add the last word\n    if current_word:\n        aggregated_predictions.append((current_word, current_entity))\n\n    return aggregated_predictions","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:31:52.324559Z","iopub.execute_input":"2024-09-19T06:31:52.324977Z","iopub.status.idle":"2024-09-19T06:31:52.334761Z","shell.execute_reply.started":"2024-09-19T06:31:52.324941Z","shell.execute_reply":"2024-09-19T06:31:52.333653Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def analyze(sentence):\n    with torch.no_grad():\n        inputs = tokenizer(sentence, return_tensors=\"pt\")\n        print(\"analyze_input\",inputs)\n        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n        print(\"tokens\",tokens)\n        outputs = model(**inputs).logits\n        print(\"outputs\",outputs)\n        predictions = torch.argmax(outputs, dim=2)\n        print(\"predictions\",predictions)\n        word_predictions = aggregate_word_level_predictions(tokens, predictions[0], dataset)\n        print(\"word_predictions\",word_predictions)\n        return {word: entity for word, entity in word_predictions}","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:31:57.598280Z","iopub.execute_input":"2024-09-19T06:31:57.599167Z","iopub.status.idle":"2024-09-19T06:31:57.607625Z","shell.execute_reply.started":"2024-09-19T06:31:57.599127Z","shell.execute_reply":"2024-09-19T06:31:57.606223Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"text=\"not at all i am no not \"  #\"not\", \"at\", \"all\", \"i\", \"am\", \"asli\", \"van\", \"wolferen\"\nanalyze(text)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T06:43:46.807830Z","iopub.execute_input":"2024-09-19T06:43:46.808581Z","iopub.status.idle":"2024-09-19T06:43:46.903633Z","shell.execute_reply.started":"2024-09-19T06:43:46.808538Z","shell.execute_reply":"2024-09-19T06:43:46.902712Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"analyze_input {'input_ids': tensor([[ 101, 1136, 1120, 1155,  178, 1821, 1185, 1136,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\ntokens ['[CLS]', 'not', 'at', 'all', 'i', 'am', 'no', 'not', '[SEP]']\noutputs tensor([[[10.3798, -1.2104, -1.1759, -1.7893, -1.1212, -1.3278, -1.0857,\n          -1.3441, -1.3477],\n         [10.7368, -1.4306, -1.1729, -1.6698, -1.1264, -1.3050, -1.2019,\n          -1.4658, -1.3785],\n         [10.6712, -1.1913, -1.2801, -1.6008, -1.1140, -1.3716, -1.1806,\n          -1.6142, -1.3119],\n         [10.6658, -1.2626, -1.0853, -1.7277, -1.1187, -1.3363, -1.2859,\n          -1.5139, -1.3117],\n         [10.7467, -1.0718, -1.1834, -1.6853, -1.1443, -1.3569, -1.2845,\n          -1.4553, -1.4184],\n         [10.6376, -0.6513, -1.2209, -1.8052, -1.0854, -1.3287, -1.3430,\n          -1.6658, -1.4340],\n         [ 1.9586,  3.2967,  5.6409, -1.8571, -1.3867, -1.9369, -1.9718,\n          -2.1170, -1.9145],\n         [ 3.2959,  0.6518,  5.7495, -1.7633, -1.5011, -1.6961, -1.2413,\n          -1.7197, -1.4554],\n         [ 5.7853, -0.1560,  0.0207, -0.9179, -0.7559, -1.3088, -0.9938,\n          -1.0113, -0.7575]]])\npredictions tensor([[0, 0, 0, 0, 0, 0, 2, 2, 0]])\ntokenized_sentence ['[CLS]', 'not', 'at', 'all', 'i', 'am', 'no', 'not', '[SEP]']\npredictions tensor([0, 0, 0, 0, 0, 0, 2, 2, 0])\ncurrent_word \ncurrent_entity O\ncurrent_word not\ncurrent_entity O\naggregated_predictions [('not', 'O')]\ncurrent_word at\ncurrent_entity O\naggregated_predictions [('not', 'O'), ('at', 'O')]\ncurrent_word all\ncurrent_entity O\naggregated_predictions [('not', 'O'), ('at', 'O'), ('all', 'O')]\ncurrent_word i\ncurrent_entity O\naggregated_predictions [('not', 'O'), ('at', 'O'), ('all', 'O'), ('i', 'O')]\ncurrent_word am\ncurrent_entity O\naggregated_predictions [('not', 'O'), ('at', 'O'), ('all', 'O'), ('i', 'O'), ('am', 'O')]\ncurrent_word no\ncurrent_entity I-PER\naggregated_predictions [('not', 'O'), ('at', 'O'), ('all', 'O'), ('i', 'O'), ('am', 'O'), ('no', 'I-PER')]\ncurrent_word not\ncurrent_entity I-PER\naggregated_predictions [('not', 'O'), ('at', 'O'), ('all', 'O'), ('i', 'O'), ('am', 'O'), ('no', 'I-PER'), ('not', 'I-PER')]\ncurrent_word \ncurrent_entity O\nword_predictions [('not', 'O'), ('at', 'O'), ('all', 'O'), ('i', 'O'), ('am', 'O'), ('no', 'I-PER'), ('not', 'I-PER')]\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'not': 'I-PER', 'at': 'O', 'all': 'O', 'i': 'O', 'am': 'O', 'no': 'I-PER'}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}